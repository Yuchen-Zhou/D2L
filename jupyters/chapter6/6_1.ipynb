{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 从全连接层到卷积\n",
    "在之前猫狗分类的例子中：假设我们有一个足够充分的照片数据集，数据集中是拥有标注的照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度。即使将隐藏层维度降低到1000，这个全连接层也将有$10^6 \\times 10^3 = 10^9$个参数。想要训练这个模型将不可实现，因为需要大量的GPU、分布式优化训练的经验和耐心。\n",
    "卷积神经网络(Convolutional Neural Network，CNN)是机器学习利用自然图像中一些已知结构的创造性方法\n",
    "\n",
    "### 6.1.1 不变性\n",
    "想象一下，假设你想从一张图片中找到某个物体。合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。理想情况下，我们的系统应该能利用常识：猪通常不在天上飞，飞机通常不在水里游泳。但是，如果一只猪出现在图片的顶部，我们还是应该认出它来。我们可以从儿童游戏“沃尔多在哪里”中得到灵感：在这个游戏中包含了许多充斥着活动的混乱场景，而沃尔多通常潜伏在一些不太可能的位置，读者的目标就是找到她。尽管沃尔多的装扮很有特点，但是在眼花缭乱的场景中找到他也很有难度。然而沃尔多的样子并不取决于他潜藏的地方，因此我们可以使用一个“沃尔多检测器”扫描图像。该检测器将图像分割成多个区域，并为每个区域包含沃尔多的可能性打分。卷积神经网络正是将空间不变形(spatial invariance)的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。\n",
    "\n",
    "<div align=center>\n",
    "<img src='../../pics/6_1.jpeg' width='50%'>\n",
    "</div>\n",
    "\n",
    "现在，我们将上述想法总结一下，从而帮助我们设计适合于计算机视觉的神经网络架构：\n",
    "\n",
    "1. 平移不变性(translation invariance)：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”\n",
    "2. 局部性(locality)：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远的区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
